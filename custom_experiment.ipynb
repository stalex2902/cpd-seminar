{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58ac3252",
   "metadata": {},
   "source": [
    "# Experiments with custom models and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0747627e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing our utils\n",
    "from utils import datasets, metrics, core_models, cpd_models, klcpd, tscp\n",
    "from utils.model_utils import fix_seeds\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e8c427",
   "metadata": {},
   "source": [
    "## Fix seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59c0d822",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "fix_seeds(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497fbf62",
   "metadata": {},
   "source": [
    "## Create dataset\n",
    "\n",
    "You should define your own CustomDataset class with self.data and self.labels and then use our CPDDatasets wrapper.For example, we take our HumanActivityDataset defined in utils/datasets.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0100e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments_name = \"human_activity\"\n",
    "train_dataset, test_dataset = datasets.CPDDatasets(experiments_name=experiments_name).get_dataset_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8435185",
   "metadata": {},
   "source": [
    "## Define your custom core model\n",
    "\n",
    "You should use torch.nn.Module wrapper for your core model and define self.forward method. For example, we take our BaseRnn model defined in utils/core_models.py. We use default parameters (specified in configs/human_activity_seq2seq.yaml file)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f0b9741",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.25 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "# define core model for an experiment with our 'indid' loss\n",
    "core_model_indid = core_models.BaseRnn(\n",
    "    input_size=28,\n",
    "    hidden_dim=8,\n",
    "    n_layers=1,\n",
    "    drop_prob=0.25\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4593b40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary with default arguments for consistency with our interface\n",
    "# define arguments as they are set in the corresponding config file\n",
    "learning = dict()\n",
    "learning[\"batch_size\"] = 16\n",
    "learning[\"lr\"] = 0.001\n",
    "learning[\"epochs\"] = 5\n",
    "learning[\"grad_clip\"] = 0.0\n",
    "\n",
    "loss = dict()\n",
    "loss[\"T\"] = 5\n",
    "\n",
    "args = dict()\n",
    "args[\"learning\"] = learning\n",
    "args[\"loss\"] = loss\n",
    "\n",
    "args[\"experiments_name\"] = experiments_name\n",
    "args[\"num_workers\"] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea1de514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define CPDModel with our 'indid' loss\n",
    "indid_model = cpd_models.CPDModel(\n",
    "    loss_type=\"indid\",\n",
    "    args=args,\n",
    "    model=core_model_indid,\n",
    "    train_dataset=train_dataset,\n",
    "    test_dataset=test_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c17c3a",
   "metadata": {},
   "source": [
    "## Train the model using pytorch_lightning.trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2670f554",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name  | Type    | Params\n",
      "----------------------------------\n",
      "0 | model | BaseRnn | 1.2 K \n",
      "1 | loss  | CPDLoss | 0     \n",
      "----------------------------------\n",
      "1.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.2 K     Total params\n",
      "0.005     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/opt/anaconda3/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:240: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "085338198607425985b48e0f3fc8ce52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# use logger\n",
    "model_name = f'seq2seq_indid_seed_{SEED}'\n",
    "logger = TensorBoardLogger(save_dir=f'logs/{experiments_name}', name=model_name)\n",
    "\n",
    "# define trainer with custom parameters\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    gpus=0,\n",
    "    benchmark=True,\n",
    "    check_val_every_n_epoch=1,\n",
    "    gradient_clip_val=0.,\n",
    "    logger=logger,\n",
    "    \n",
    "    # use early stopping\n",
    "    callbacks=EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=10)\n",
    ")\n",
    "\n",
    "trainer.fit(indid_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e87f0ff",
   "metadata": {},
   "source": [
    "## Evaluate your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1660d56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                   | 0/102 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "expected scalar type Double but found Float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m threshold_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39mthreshold_list))\n\u001b[1;32m      5\u001b[0m threshold_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.001\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlist\u001b[39m(threshold_list) \u001b[38;5;241m+\u001b[39m [\u001b[38;5;241m1.001\u001b[39m]\n\u001b[1;32m      7\u001b[0m metrics_local, delay_list, fp_delay_list \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m----> 8\u001b[0m     \u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluation_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindid_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mindid_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mthreshold_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# choose 'cpu' or 'cuda' if available\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseq2seq\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m                               \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/InDiD/code/utils/metrics.py:389\u001b[0m, in \u001b[0;36mevaluation_pipeline\u001b[0;34m(model, test_dataloader, threshold_list, device, verbose, model_type, subseq_len, scale)\u001b[0m\n\u001b[1;32m    378\u001b[0m confusion_matrix_dict \u001b[38;5;241m=\u001b[39m {}    \n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m threshold \u001b[38;5;129;01min\u001b[39;00m tqdm(threshold_list):\n\u001b[1;32m    381\u001b[0m     (\n\u001b[1;32m    382\u001b[0m         TN,\n\u001b[1;32m    383\u001b[0m         FP,\n\u001b[1;32m    384\u001b[0m         FN,\n\u001b[1;32m    385\u001b[0m         TP,\n\u001b[1;32m    386\u001b[0m         mean_delay,\n\u001b[1;32m    387\u001b[0m         mean_fp_delay,\n\u001b[1;32m    388\u001b[0m         cover\n\u001b[0;32m--> 389\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_metrics_on_set\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubseq_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubseq_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscale\u001b[49m\n\u001b[1;32m    398\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    400\u001b[0m     confusion_matrix_dict[threshold] \u001b[38;5;241m=\u001b[39m (TN, FP, FN, TP)\n\u001b[1;32m    401\u001b[0m     delay_dict[threshold] \u001b[38;5;241m=\u001b[39m mean_delay\n",
      "File \u001b[0;32m~/Desktop/InDiD/code/utils/metrics.py:189\u001b[0m, in \u001b[0;36mevaluate_metrics_on_set\u001b[0;34m(model, test_loader, threshold, verbose, model_type, subseq_len, device, scale)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m test_inputs, test_labels \u001b[38;5;129;01min\u001b[39;00m test_loader:\n\u001b[0;32m--> 189\u001b[0m         test_out, test_labels \u001b[38;5;241m=\u001b[39m \u001b[43mget_models_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43msubseq_len\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubseq_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m                                                       \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    197\u001b[0m             test_out \u001b[38;5;241m=\u001b[39m test_out\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m2\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/InDiD/code/utils/metrics.py:149\u001b[0m, in \u001b[0;36mget_models_predictions\u001b[0;34m(inputs, labels, model, model_type, subseq_len, device, scale)\u001b[0m\n\u001b[1;32m    147\u001b[0m     outs \u001b[38;5;241m=\u001b[39m klcpd\u001b[38;5;241m.\u001b[39mget_klcpd_output_scaled(model, inputs, model\u001b[38;5;241m.\u001b[39mwindow_1, model\u001b[38;5;241m.\u001b[39mwindow_2, scale\u001b[38;5;241m=\u001b[39mscale)\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 149\u001b[0m     outs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outs, true_labels\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/InDiD/code/utils/cpd_models.py:151\u001b[0m, in \u001b[0;36mCPDModel.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    146\u001b[0m     \u001b[38;5;124;03m\"\"\"Forward step for CPD model.\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \n\u001b[1;32m    148\u001b[0m \u001b[38;5;124;03m    :param inputs: batch of data\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;124;03m    :return: predictions\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__preprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/InDiD/code/utils/core_models.py:41\u001b[0m, in \u001b[0;36mBaseRnn.forward\u001b[0;34m(self, input_seq)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m\"\"\"Forward propagation through model.\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \n\u001b[1;32m     37\u001b[0m \u001b[38;5;124;03m:param input_seq: batch of generated sunthetic normal sequences\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03m:return: probabilities of changes for each sequence\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     40\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m input_seq\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 41\u001b[0m lstm_out, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_seq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m lstm_out \u001b[38;5;241m=\u001b[39m lstm_out\u001b[38;5;241m.\u001b[39mcontiguous()\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_dim)\n\u001b[1;32m     43\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(lstm_out)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/torch/nn/modules/rnn.py:761\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    759\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_forward_args(\u001b[38;5;28minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m    760\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 761\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    762\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    764\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[1;32m    765\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expected scalar type Double but found Float"
     ]
    }
   ],
   "source": [
    "# create list of thresholds from [0, 1]\n",
    "threshold_number = 100\n",
    "threshold_list = np.linspace(-5, 5, threshold_number)\n",
    "threshold_list = 1 / (1 + np.exp(-threshold_list))\n",
    "threshold_list = [-0.001] + list(threshold_list) + [1.001]\n",
    "\n",
    "metrics_local, delay_list, fp_delay_list = \\\n",
    "    metrics.evaluation_pipeline(indid_model,\n",
    "                                indid_model.val_dataloader(),\n",
    "                                threshold_list,\n",
    "                                device=\"cpu\", # choose 'cpu' or 'cuda' if available\n",
    "                                model_type=\"seq2seq\",\n",
    "                                verbose=True\n",
    "                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9395a582",
   "metadata": {},
   "source": [
    "## Draw detection curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9284ee04",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "plt.plot(fp_delay_list.values(), delay_list.values(), '-o', markersize=8, label=\"InDiD\")\n",
    "plt.xlabel('Mean Time to False Alarm', fontsize=28)\n",
    "plt.ylabel('Mean Detection Delay', fontsize=28)\n",
    "plt.xticks(fontsize=24)\n",
    "plt.yticks(fontsize=24)\n",
    "plt.legend(loc='upper left', fontsize=26)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90f3408",
   "metadata": {},
   "source": [
    "## The same experiment with BCE loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe1fcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define core model for an experiment with 'bce' loss\n",
    "core_model_bce = core_models.BaseRnn(\n",
    "    input_size=28,\n",
    "    hidden_dim=8,\n",
    "    n_layers=1,\n",
    "    drop_prob=0.25\n",
    ")\n",
    "\n",
    "# define CPDModel with 'bce' loss\n",
    "bce_model = cpd_models.CPDModel(\n",
    "    loss_type=\"indid\",\n",
    "    args=args,\n",
    "    model=core_model_bce,\n",
    "    train_dataset=train_dataset,\n",
    "    test_dataset=test_dataset\n",
    ")\n",
    "\n",
    "# use logger\n",
    "model_name = f'seq2seq_bce_seed_{SEED}'\n",
    "logger = TensorBoardLogger(save_dir=f'logs/{experiments_name}', name=model_name)\n",
    "\n",
    "# define trainer with custom parameters\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    gpus=0,\n",
    "    benchmark=True,\n",
    "    check_val_every_n_epoch=1,\n",
    "    gradient_clip_val=0.,\n",
    "    logger=logger,\n",
    "    \n",
    "    # use early stopping\n",
    "    callbacks=EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=10)\n",
    ")\n",
    "\n",
    "trainer.fit(bce_model)\n",
    "\n",
    "# evaluate model\n",
    "metrics_local, delay_list, fp_delay_list = \\\n",
    "    metrics.evaluation_pipeline(bce_model,\n",
    "                                bce_model.val_dataloader(),\n",
    "                                threshold_list,\n",
    "                                device=\"cpu\", # choose 'cpu' or 'cuda' if available\n",
    "                                model_type=\"seq2seq\",\n",
    "                                verbose=True\n",
    "                               )\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.plot(fp_delay_list.values(), delay_list.values(), '-o', markersize=8, label=\"BCE\")\n",
    "plt.xlabel('Mean Time to False Alarm', fontsize=28)\n",
    "plt.ylabel('Mean Detection Delay', fontsize=28)\n",
    "plt.xticks(fontsize=24)\n",
    "plt.yticks(fontsize=24)\n",
    "plt.legend(loc='upper left', fontsize=26)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7df4ec0",
   "metadata": {},
   "source": [
    "## The same experiment with 'Combined' loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3e778b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define core model for an experiment with 'combined' loss\n",
    "core_model_combined = core_models.BaseRnn(\n",
    "    input_size=28,\n",
    "    hidden_dim=8,\n",
    "    n_layers=1,\n",
    "    drop_prob=0.25\n",
    ")\n",
    "\n",
    "# define 2 CPDModels for this experiment\n",
    "# note that they share the one and the same core model \n",
    "combined_model_1 = cpd_models.CPDModel(\n",
    "    loss_type=\"bce\",\n",
    "    args=args,\n",
    "    model=core_model_combined,\n",
    "    train_dataset=train_dataset,\n",
    "    test_dataset=test_dataset\n",
    ")\n",
    "\n",
    "combined_model_2 = cpd_models.CPDModel(\n",
    "    loss_type=\"indid\",\n",
    "    args=args,\n",
    "    model=core_model_combined,\n",
    "    train_dataset=train_dataset,\n",
    "    test_dataset=test_dataset\n",
    ")\n",
    "\n",
    "# use logger\n",
    "model_name = f'seq2seq_combined_seed_{SEED}'\n",
    "logger = TensorBoardLogger(save_dir=f'logs/{experiments_name}', name=model_name)\n",
    "\n",
    "# define trainer with custom parameters\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=10,\n",
    "    gpus=0,\n",
    "    benchmark=True,\n",
    "    check_val_every_n_epoch=1,\n",
    "    gradient_clip_val=0.,\n",
    "    logger=logger,\n",
    "    \n",
    "    # use early stopping\n",
    "    callbacks=EarlyStopping(monitor=\"val_loss\", min_delta=0, patience=10)\n",
    ")\n",
    "\n",
    "trainer.fit(combined_model_1)\n",
    "trainer.fit(combined_model_2)\n",
    "\n",
    "# evaluate model\n",
    "metrics_local, delay_list, fp_delay_list = \\\n",
    "    metrics.evaluation_pipeline(combined_model_2, # use the second model for evaluation\n",
    "                                combined_model_2.val_dataloader(),\n",
    "                                threshold_list,\n",
    "                                device=\"cpu\", # choose 'cpu' or 'cuda' if available\n",
    "                                model_type=\"seq2seq\",\n",
    "                                verbose=True\n",
    "                               )\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.plot(fp_delay_list.values(), delay_list.values(), '-o', markersize=8, label=\"Combined\")\n",
    "plt.xlabel('Mean Time to False Alarm', fontsize=28)\n",
    "plt.ylabel('Mean Detection Delay', fontsize=28)\n",
    "plt.xticks(fontsize=24)\n",
    "plt.yticks(fontsize=24)\n",
    "plt.legend(loc='upper left', fontsize=26)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d80a761",
   "metadata": {},
   "source": [
    "## Experiments with KL-CPD baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f748f40b",
   "metadata": {},
   "source": [
    "### Initializing core models: Discriminator and Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d4044a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80d762cf",
   "metadata": {},
   "source": [
    "## Experiments with TS-CP2 baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a18dca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
